import { streamText } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";
import {
  TestCase,
  AutoGeneratedTests,
  CodeExecution,
  ExecutionContext,
  testCaseSchema,
  autoGeneratedTestsSchema,
} from "./codeExecutor/types";
import { cacheManager } from "./cacheManager";
import { performanceMonitor } from "./performanceMonitor";

// Logger estructurado
class Logger {
  private context: string;

  constructor(context: string) {
    this.context = context;
  }

  info(message: string, data?: any): void {
    console.log(
      `[${this.context}] INFO: ${message}`,
      data ? JSON.stringify(data, null, 2) : ""
    );
  }

  warn(message: string, data?: any): void {
    console.warn(
      `[${this.context}] WARN: ${message}`,
      data ? JSON.stringify(data, null, 2) : ""
    );
  }

  error(message: string, error?: any): void {
    console.error(
      `[${this.context}] ERROR: ${message}`,
      error ? JSON.stringify(error, null, 2) : ""
    );
  }

  debug(message: string, data?: any): void {
    if (process.env.NODE_ENV === "development") {
      console.debug(
        `[${this.context}] DEBUG: ${message}`,
        data ? JSON.stringify(data, null, 2) : ""
      );
    }
  }
}

// Schemas adicionales para test generation
const testGenerationRequestSchema = z.object({
  code: z.string().min(1),
  language: z.enum([
    "python",
    "javascript",
    "sql",
    "bash",
    "typescript",
    "java",
    "cpp",
    "go",
  ]),
  functionName: z.string().optional(),
  description: z.string().optional(),
  testTypes: z
    .array(z.enum(["unit", "integration", "edge", "performance"]))
    .optional(),
  maxTests: z.number().min(1).max(20).optional(),
});

const testResultSchema = z.object({
  testCase: testCaseSchema,
  passed: z.boolean(),
  output: z.any(),
  error: z.string().optional(),
  executionTime: z.number(),
  memoryUsage: z.number().optional(),
});

export interface TestGenerationRequest
  extends z.infer<typeof testGenerationRequestSchema> {}
export interface TestResult extends z.infer<typeof testResultSchema> {}

export class TestGenerator {
  private static instance: TestGenerator;
  private logger: Logger;
  private testTemplates: Map<string, string[]> = new Map();
  private testResults: Map<string, TestResult[]> = new Map();

  private constructor() {
    this.logger = new Logger("TestGenerator");
    this.initializeTestTemplates();
  }

  static getInstance(): TestGenerator {
    if (!TestGenerator.instance) {
      TestGenerator.instance = new TestGenerator();
    }
    return TestGenerator.instance;
  }

  async generateTests(
    code: string,
    language: string,
    options: {
      functionName?: string;
      description?: string;
      testTypes?: Array<"unit" | "integration" | "edge" | "performance">;
      maxTests?: number;
      context?: ExecutionContext;
    } = {}
  ): Promise<AutoGeneratedTests> {
    const startTime = Date.now();

    try {
      // Validar que el lenguaje sea uno de los soportados
      const supportedLanguages = [
        "python",
        "javascript",
        "sql",
        "bash",
        "typescript",
        "java",
        "cpp",
        "go",
      ] as const;

      const validatedLanguage = supportedLanguages.includes(language as any)
        ? (language as (typeof supportedLanguages)[number])
        : "javascript"; // fallback

      // Validar entrada
      const request: TestGenerationRequest = {
        code,
        language: validatedLanguage,
        functionName: options.functionName,
        description: options.description,
        testTypes: options.testTypes || ["unit", "edge"],
        maxTests: options.maxTests || 5,
      };

      const validatedRequest = testGenerationRequestSchema.parse(request);

      // Intentar obtener del cache
      const cacheKey = `test_generation:${this.hashCode(
        code + validatedLanguage + JSON.stringify(options)
      )}`;
      const cached = await cacheManager.get<AutoGeneratedTests>(cacheKey);
      if (cached) {
        this.logger.info(`Tests retrieved from cache`, {
          language: validatedLanguage,
          testCount: cached.testCases.length,
        });
        return cached;
      }

      // Generar tests con IA
      const generatedTests = await this.generateTestsWithAI(
        validatedRequest,
        options.context
      );

      // Validar resultado con Zod
      const validatedTests = autoGeneratedTestsSchema.parse(generatedTests);

      // Cachear resultado
      await cacheManager.set(cacheKey, validatedTests, { ttl: 3600 }); // 1 hora

      // Registrar métricas
      performanceMonitor.recordMetric(
        "tests_generated",
        Date.now() - startTime,
        true,
        undefined,
        {
          language: validatedLanguage,
          testCount: validatedTests.testCases.length,
          coverage: validatedTests.coverage,
        }
      );

      this.logger.info(`Tests generated successfully`, {
        language: validatedLanguage,
        testCount: validatedTests.testCases.length,
        coverage: validatedTests.coverage,
        confidence: validatedTests.confidence,
      });

      return validatedTests;
    } catch (error) {
      this.logger.error(`Failed to generate tests`, error);
      performanceMonitor.recordError(
        "test_generation_failed",
        error instanceof Error ? error.message : "Unknown error"
      );

      // Retornar tests básicos como fallback
      return this.generateFallbackTests(code, language);
    }
  }

  async runTests(
    tests: AutoGeneratedTests,
    code: string,
    language: string,
    context?: ExecutionContext
  ): Promise<{
    results: TestResult[];
    summary: {
      total: number;
      passed: number;
      failed: number;
      successRate: number;
      averageExecutionTime: number;
      coverage: number;
    };
  }> {
    const startTime = Date.now();

    try {
      const results: TestResult[] = [];
      let totalExecutionTime = 0;

      for (const testCase of tests.testCases) {
        const testStartTime = Date.now();

        try {
          // Ejecutar el test
          const result = await this.executeTestCase(
            testCase,
            code,
            language,
            context
          );
          results.push(result);
          totalExecutionTime += result.executionTime;
        } catch (error) {
          // Test falló
          const failedResult: TestResult = {
            testCase,
            passed: false,
            output: null,
            error: error instanceof Error ? error.message : "Unknown error",
            executionTime: Date.now() - testStartTime,
          };
          results.push(failedResult);
          totalExecutionTime += failedResult.executionTime;
        }
      }

      // Calcular estadísticas
      const passedTests = results.filter((r) => r.passed).length;
      const failedTests = results.filter((r) => !r.passed).length;
      const successRate =
        results.length > 0 ? (passedTests / results.length) * 100 : 0;
      const averageExecutionTime =
        results.length > 0 ? totalExecutionTime / results.length : 0;

      // Registrar métricas
      performanceMonitor.recordMetric(
        "tests_executed",
        Date.now() - startTime,
        true,
        undefined,
        {
          language,
          totalTests: results.length,
          passedTests: passedTests,
          successRate: successRate,
        }
      );

      this.logger.info(`Tests executed successfully`, {
        language,
        totalTests: results.length,
        passedTests,
        successRate,
        averageExecutionTime,
      });

      return {
        results,
        summary: {
          total: results.length,
          passed: passedTests,
          failed: failedTests,
          successRate,
          averageExecutionTime,
          coverage: tests.coverage,
        },
      };
    } catch (error) {
      this.logger.error(`Failed to execute tests`, error);
      performanceMonitor.recordError(
        "test_execution_failed",
        error instanceof Error ? error.message : "Unknown error"
      );

      return {
        results: [],
        summary: {
          total: 0,
          passed: 0,
          failed: 0,
          successRate: 0,
          averageExecutionTime: 0,
          coverage: 0,
        },
      };
    }
  }

  async optimizeTests(
    tests: AutoGeneratedTests,
    executionResults: TestResult[],
    context?: ExecutionContext
  ): Promise<AutoGeneratedTests> {
    const startTime = Date.now();

    try {
      // Analizar resultados de ejecución
      const failedTests = executionResults.filter((r) => !r.passed);
      const slowTests = executionResults.filter((r) => r.executionTime > 1000);

      if (failedTests.length === 0 && slowTests.length === 0) {
        this.logger.info(`No optimization needed`, {
          totalTests: tests.testCases.length,
        });
        return tests;
      }

      // Generar tests optimizados con IA
      const optimizationPrompt = this.buildOptimizationPrompt(
        tests,
        executionResults
      );
      const optimizedTests = await this.generateOptimizedTestsWithAI(
        optimizationPrompt,
        context
      );

      // Validar resultado
      const validatedTests = autoGeneratedTestsSchema.parse(optimizedTests);

      // Registrar métricas
      performanceMonitor.recordMetric(
        "tests_optimized",
        Date.now() - startTime,
        true,
        undefined,
        {
          originalTestCount: tests.testCases.length,
          optimizedTestCount: validatedTests.testCases.length,
          failedTestsCount: failedTests.length,
          slowTestsCount: slowTests.length,
        }
      );

      this.logger.info(`Tests optimized successfully`, {
        originalTestCount: tests.testCases.length,
        optimizedTestCount: validatedTests.testCases.length,
        failedTestsCount: failedTests.length,
        slowTestsCount: slowTests.length,
      });

      return validatedTests;
    } catch (error) {
      this.logger.error(`Failed to optimize tests`, error);
      performanceMonitor.recordError(
        "test_optimization_failed",
        error instanceof Error ? error.message : "Unknown error"
      );
      return tests; // Retornar tests originales en caso de error
    }
  }

  async getTestCoverage(
    code: string,
    tests: AutoGeneratedTests,
    language: string
  ): Promise<{
    lineCoverage: number;
    branchCoverage: number;
    functionCoverage: number;
    uncoveredLines: number[];
    uncoveredBranches: string[];
    uncoveredFunctions: string[];
  }> {
    const startTime = Date.now();

    try {
      // Simular análisis de cobertura
      const lines = code.split("\n").length;
      const coveredLines = Math.floor(lines * 0.8); // 80% cobertura simulada
      const uncoveredLines = Array.from(
        { length: lines - coveredLines },
        (_, i) => coveredLines + i + 1
      );

      const coverage = {
        lineCoverage: (coveredLines / lines) * 100,
        branchCoverage: 75, // Simulado
        functionCoverage: 85, // Simulado
        uncoveredLines,
        uncoveredBranches: [],
        uncoveredFunctions: [],
      };

      // Registrar métricas
      performanceMonitor.recordMetric(
        "test_coverage_analyzed",
        Date.now() - startTime,
        true,
        undefined,
        {
          language,
          lineCoverage: coverage.lineCoverage,
          branchCoverage: coverage.branchCoverage,
          functionCoverage: coverage.functionCoverage,
        }
      );

      return coverage;
    } catch (error) {
      this.logger.error(`Failed to analyze test coverage`, error);
      performanceMonitor.recordError(
        "test_coverage_analysis_failed",
        error instanceof Error ? error.message : "Unknown error"
      );

      return {
        lineCoverage: 0,
        branchCoverage: 0,
        functionCoverage: 0,
        uncoveredLines: [],
        uncoveredBranches: [],
        uncoveredFunctions: [],
      };
    }
  }

  async getTestStats(userId?: string): Promise<{
    totalTestsGenerated: number;
    totalTestsExecuted: number;
    averageSuccessRate: number;
    averageCoverage: number;
    mostTestedLanguage: string;
    testGenerationTime: number;
    testExecutionTime: number;
  }> {
    const startTime = Date.now();

    try {
      // Simular estadísticas
      const stats = {
        totalTestsGenerated: 150,
        totalTestsExecuted: 120,
        averageSuccessRate: 85.5,
        averageCoverage: 78.2,
        mostTestedLanguage: "javascript",
        testGenerationTime: 2.3,
        testExecutionTime: 1.8,
      };

      // Registrar métricas
      performanceMonitor.recordMetric(
        "test_stats_retrieved",
        Date.now() - startTime,
        true,
        undefined,
        {
          userId: userId || "all",
          totalTestsGenerated: stats.totalTestsGenerated,
          totalTestsExecuted: stats.totalTestsExecuted,
        }
      );

      return stats;
    } catch (error) {
      this.logger.error(`Failed to get test stats`, error);
      performanceMonitor.recordError(
        "test_stats_retrieval_failed",
        error instanceof Error ? error.message : "Unknown error"
      );

      return {
        totalTestsGenerated: 0,
        totalTestsExecuted: 0,
        averageSuccessRate: 0,
        averageCoverage: 0,
        mostTestedLanguage: "javascript",
        testGenerationTime: 0,
        testExecutionTime: 0,
      };
    }
  }

  private async generateTestsWithAI(
    request: TestGenerationRequest,
    context?: ExecutionContext
  ): Promise<AutoGeneratedTests> {
    const prompt = this.buildTestGenerationPrompt(request);

    const result = await streamText({
      model: openai("gpt-4o"),
      messages: [
        {
          role: "system",
          content: `Eres un experto en generación de tests automatizados. Genera tests de alta calidad, completos y bien estructurados para el código proporcionado. Responde SOLO con JSON válido.`,
        },
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: 0.3,
      maxTokens: 2000,
    });

    const text = await this.getTextSafely(result);
    const parsed = JSON.parse(text);

    return {
      testCases: parsed.testCases || [],
      coverage: parsed.coverage || 0.8,
      confidence: parsed.confidence || 0.85,
      testFramework:
        request.language === "javascript"
          ? "jest"
          : request.language === "python"
          ? "pytest"
          : "default",
      executionTime: Date.now(),
    };
  }

  private async generateOptimizedTestsWithAI(
    prompt: string,
    context?: ExecutionContext
  ): Promise<AutoGeneratedTests> {
    const result = await streamText({
      model: openai("gpt-4o"),
      messages: [
        {
          role: "system",
          content: `Eres un experto en optimización de tests. Analiza los resultados de ejecución y genera tests mejorados que sean más robustos, rápidos y efectivos. Responde SOLO con JSON válido.`,
        },
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: 0.2,
      maxTokens: 2000,
    });

    const text = await this.getTextSafely(result);
    const parsed = JSON.parse(text);

    return {
      testCases: parsed.testCases || [],
      coverage: parsed.coverage || 0.85,
      confidence: parsed.confidence || 0.9,
      testFramework: parsed.testFramework || "default",
      executionTime: Date.now(),
    };
  }

  private async executeTestCase(
    testCase: TestCase,
    code: string,
    language: string,
    context?: ExecutionContext
  ): Promise<TestResult> {
    const startTime = Date.now();

    try {
      // Construir código de test según el lenguaje
      const testCode = this.buildTestCode(testCase, code, language);

      // Ejecutar el test (simulado por ahora)
      const output = await this.runTestCode(testCode, language);

      // Verificar si el test pasó
      const passed = this.verifyTestResult(testCase, output);

      return {
        testCase,
        passed,
        output,
        executionTime: Date.now() - startTime,
      };
    } catch (error) {
      return {
        testCase,
        passed: false,
        output: null,
        error: error instanceof Error ? error.message : "Unknown error",
        executionTime: Date.now() - startTime,
      };
    }
  }

  private buildTestGenerationPrompt(request: TestGenerationRequest): string {
    const { code, language, functionName, description, testTypes, maxTests } =
      request;

    return `
Genera ${maxTests} tests de alta calidad para el siguiente código en ${language}:

${functionName ? `Función: ${functionName}` : ""}
${description ? `Descripción: ${description}` : ""}

Código:
\`\`\`${language}
${code}
\`\`\`

Tipos de tests requeridos: ${testTypes?.join(", ") || "unit, edge"}

Genera tests que cubran:
- Casos normales (unit tests)
- Casos edge y límites
- Casos de error
- Diferentes tipos de entrada

Responde SOLO con JSON en este formato:
{
  "testCases": [
    {
      "input": "valor de entrada",
      "expectedOutput": "valor esperado",
      "description": "descripción del test",
      "category": "unit|integration|edge|performance"
    }
  ],
  "coverage": 0.85,
  "confidence": 0.9
}
`;
  }

  private buildOptimizationPrompt(
    tests: AutoGeneratedTests,
    executionResults: TestResult[]
  ): string {
    const failedTests = executionResults.filter((r) => !r.passed);
    const slowTests = executionResults.filter((r) => r.executionTime > 1000);

    return `
Optimiza los siguientes tests basándote en los resultados de ejecución:

Tests originales:
${JSON.stringify(tests.testCases, null, 2)}

Resultados de ejecución:
${JSON.stringify(executionResults, null, 2)}

Tests que fallaron: ${failedTests.length}
Tests lentos (>1s): ${slowTests.length}

Genera tests optimizados que:
- Corrijan los tests que fallaron
- Optimicen los tests lentos
- Mantengan la cobertura
- Sean más robustos

Responde SOLO con JSON en el mismo formato que los tests originales.
`;
  }

  private buildTestCode(
    testCase: TestCase,
    code: string,
    language: string
  ): string {
    switch (language) {
      case "javascript":
      case "typescript":
        return `
${code}

// Test
const result = (() => {
  try {
    return eval(\`${testCase.input}\`);
  } catch (error) {
    return { error: error.message };
  }
})();

console.log(JSON.stringify({
  input: ${JSON.stringify(testCase.input)},
  output: result,
  expected: ${JSON.stringify(testCase.expectedOutput)}
}));
`;

      case "python":
        return `
${code}

# Test
import json
import sys

try:
    result = eval("${testCase.input}")
    print(json.dumps({
        "input": "${testCase.input}",
        "output": result,
        "expected": ${JSON.stringify(testCase.expectedOutput)}
    }))
except Exception as e:
    print(json.dumps({
        "input": "${testCase.input}",
        "output": {"error": str(e)},
        "expected": ${JSON.stringify(testCase.expectedOutput)}
    }))
`;

      default:
        return `
${code}

// Test básico
console.log(JSON.stringify({
  input: ${JSON.stringify(testCase.input)},
  output: "Test not implemented for ${language}",
  expected: ${JSON.stringify(testCase.expectedOutput)}
}));
`;
    }
  }

  private async runTestCode(testCode: string, language: string): Promise<any> {
    // Simulación de ejecución de test
    // En producción, esto ejecutaría el código en un sandbox seguro
    return new Promise((resolve) => {
      setTimeout(() => {
        // Simular resultado exitoso
        resolve({
          input: "test input",
          output: "test output",
          expected: "test output",
        });
      }, 100);
    });
  }

  private verifyTestResult(testCase: TestCase, output: any): boolean {
    // Verificación básica de resultado
    // En producción, esto sería más sofisticado
    return output && output.output === testCase.expectedOutput;
  }

  private generateFallbackTests(
    code: string,
    language: string
  ): AutoGeneratedTests {
    // Tests básicos de fallback
    const basicTests: TestCase[] = [
      {
        input: "basic input",
        expectedOutput: "expected output",
        description: "Basic functionality test",
        category: "unit",
      },
      {
        input: "",
        expectedOutput: "error or default",
        description: "Empty input test",
        category: "edge",
      },
    ];

    return {
      testCases: basicTests,
      coverage: 0.5,
      confidence: 0.6,
      testFramework: language === "javascript" ? "jest" : "default",
      executionTime: Date.now(),
    };
  }

  private initializeTestTemplates(): void {
    // Templates básicos para diferentes lenguajes
    this.testTemplates.set("javascript", [
      "expect(result).toBe(expected)",
      "expect(result).toEqual(expected)",
      "expect(() => code()).toThrow()",
    ]);

    this.testTemplates.set("python", [
      "assert result == expected",
      "assert result is not None",
      "with pytest.raises(Exception):",
    ]);
  }

  private async getTextSafely(result: any): Promise<string> {
    try {
      let text = "";
      for await (const chunk of result.textStream) {
        text += chunk;
      }
      return text;
    } catch (error) {
      this.logger.error("Error extracting text from stream", error);
      throw new Error("Failed to extract text from AI response");
    }
  }

  private hashCode(str: string): string {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return hash.toString();
  }

  private generateId(): string {
    return `test_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
}

export const testGenerator = TestGenerator.getInstance();
